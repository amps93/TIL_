# 분류

## 220313

* 학습 데이터로 주어진 데이터의 피처와 레이블값을 머신러닝 알고리즘으로 학습해 모델을 생성하고 이렇게 생성된 모델에 새로운 데이터 값이 주어졌을 때 미지의 레이블 값에 예측하는 것
* 분류 알고리즘
  * 나이브 베이즈
  * 로지스틱 회귀
  * 결정 트리
  * 서포트 벡터 머신
  * 최소 근접 알고리즘
  * 신경망
  * 앙상블

### 결정트리

* 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리 기반의 분류 규칙을 만드는 것
* 규칙노드, 리프노드, 서브트리
* 균일도 : 어떤 데이터 세트가 얼마나 균일한 데이터 분포를 갖고 있는가
  * 균일도를 측정하는 대표적인 방법은 엔트로피를 이용한 정보이득지수와 지니계수가 있음
* 장점 : 직관적이며 쉽다, 피쳐의 스케일링이나 정규화 등의 사전 가공 영향도가 크지 않다
* 단점 : 과적합으로 알고리즘 성능이 떨어진다. 이를 극복하기 위해 트리의 크기를 사전에 제한하는 튜닝 필요

## 220314

### 앙상블 학습

* 여러개의 분류기를 생성하고 그 예측을 결합함으로써 보다 정확한 최종 예측을 도출하는 기법 (집단지성)
* 앙상블 학습의 유형
  * 보팅 : 서로 다른 알고리즘을 가진 분류기를 결합
  * 배깅 : 각각의 분류기가 모두 같은 유형의 알고리즘 기반이나, 데이터 샘플링을 서로 다르게 가져가면서 학습을 수행(랜덤 포레스트)
  * 부스팅 : 여러개의 분류기가 순차적으로 학습을 수행하되, 앞에서 학습한 분류기가 예측이 틀린 데이터에 대해서는 올바르게 예측할 수 있도록 다음 분류기에는 가중치를 부여하며 학습과 예측을 진행 (그래디언트 부스트, XGBoost, LightGBM)

#### 보팅 유형 - 하드 보팅과 소프트 보팅

* 하드보팅 : 다수결 원칙 - 예측한 결과값들중 다수의 분류기가 결정한 예측값을 최종 보팅 결과값으로 선정
* 소프트 보팅 : 분류기들의 레이블 값 결정 확률을 모두 더하고 이를 평균해서 이들 중 확률이 가장 높은 레이블 값을 최종 보팅 결과값으로 선정
* 일반적으로 소프트 보팅이 보팅 방법으로 적용됨

#### 보팅 분류기

### 랜덤 포레스트

* 배깅의 대표적인 알고리즘
* 결정트리 기반 알고리즘
* 앙상블 알고리즘 중 비교적 빠른 수행속도
* 다양한 영역에서 높은 예측 성능을 보임
* 여러개의 결정트리 분류기가 전체 데이터에서 배깅 방식으로 각자의 데이터를 샘플링해 개별적으로 학습을 수행한 뒤 최종적으로 모든 분류기가 보팅을 통해 예측 결정

#### 부트스트래핑

* 랜덤 포레스트의 개별 분류기 기반 알고리즘은 결정트리이지만 개별 트리가 학습하는 데이터 세트는 전체 데이터에서 일부가 중첩되게 샘플링된 데이터 세트
* 이렇게 여러 개의 데이터 세트를 중첩되게 분리하는 것을 **부트스트래핑 분할 방식** 이라고 한다
  * 교차검증과 다른점은 교차검증의 경우 데이터가 중복되지 않는다는 점

#### 랜덤 포레스트 하이퍼 파라미터 및 튜닝

### GBM(Gradient Boosting Machine)

* 부스팅 알고리즘은 여러개의 약한 학습기를 순차적으로 학습-예측하면서 잘못 예측한 데이터에 가중치 부여를 통해 오류를 개선해 나가면서 학습하는 방식

* 대표적으로 에이다 부스트(Adaptive boosting)와 그래디언트 부스트가 있음

* 일반적으로 GBM이 랜덤포레스트보다 예측 성능이 뛰어난 경우가 많음
* 하지만 수행시간이 오래걸리며, 그만큼 하이퍼 파라미터 튜닝 노력도 더 필요함

#### GBM 하이퍼 파라미터 및 튜닝

### XGBoost

* GBM에 기반하고 있음
* GBM의 단점인 느린 수행 시간 및 과적합 규제 부재 등의 문제를 해결함
* XGBoost의 장점
  * 뛰어난 예측 성능
  * GBM 대비 빠른 수행 시간
  * 과적합 규제
  * Tree Pruning(나무가지 치기)
  * 자체 내장된 교차 검증
  * 결손값 자체 처리



