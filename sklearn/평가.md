# 평가

## ----220307----

* 정확도 accuracy
* 오차행렬 confusion matrix
* 정밀도 precision
* 재현율 recall
* F1 스코어
* ROC AUC

### 정확도

* 정확도 = 예측결과가 동일한 데이터 건수/전체 예측 데이터 건수
* 가장 직관적인 평가 지표
* 불균형한 자료에 적합하지 않음

### 오차행렬

* 이진분류에서 자주 활용됨
* 0 : Negative, 1 : Positive 
  * TN : 예측값 0, 실제값 0
  * FP : 예측값 1, 실제값 0 
  * FN : 예측값 0, 실제값 1
  * TP : 예측값 1, 실제값 1

### 정밀도와 재현율

* 정밀도 = TP/(FP+TP)
  * 예측을 Positive로 한 대상중 예측과 실제값이 Positive인 비율
  * 스팸메일 여부 판단
* 재현율 = TP/(FN+TP)
  * 실제값이 Positive인 대상중 예측과 실제값이 Positive인 비율
  * 실제 Positive 데이터를 Negative로 판단하면 업무상 영향이 큰 경우에 중요한 지표 (ex. 암 판단 모델, 보험사기 같은 금융사기 모델)
* 일반적으로 재현율이 정밀도보다 상대적으로 중요한 업무가 많음

#### 정밀도/재현율 트레이드 오프

* 임곗값(Threshold)를 조정해 정밀도 또는 재현율 수치를 높일 수 있음
* 주요 메서드 : predict_proba(), Binarizer()

### F1 스코어

* 정밀도와 재현율을 결합한 지표
* 정밀도와 재현율이 어느 한쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 가짐

### ROC곡선과 AUC

* ROC(Receiver operating characteristic) 도표
  * 분류의 결정 임계값(threshold)에 따라 달라지는 TPR(민감도, sensitivity)과 FPR(1-특이도, 1-specificity)의 조합을 도표로 나타냄

    1. TPR - True Positive Rate(=sensitivity(민감도)) : 1인 케이스에 대해 1로 잘 예측한 비율

    2. FPR - False Positive Rate(=1-specificity(특이도)) : 0인 케이스에 대해 1로 잘못 예측한 비율

    3. 임계값이 1이면 FPR=0, TPR=0

    4. 임계값을 1에서 0으로 낮춰감에 따라 FPR과 TPR은 동시에 증가함

    5. FPR이 증가하는 정도보다 TPR이 빠르게 증가하면 이상적 -> 왼쪽 위 꼭지점에 가까울수록 좋음

* AUC(Area under the curve)

  * ROC 곡선 아래의 면적
  * 가운데 대각선의 직선은 랜덤한 수준의 이진분류에 대응되며, 이 경우 AUC는 0.5임
  * 1에 가까울수록 좋은 수치. FPR이 작을 때 얼마나 큰 TPR을 얻는지에 따라 결정됨