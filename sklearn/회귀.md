# 회귀

## 220324

| 독립변수 개수      | 회귀 계수위 결합     |
| ------------------ | -------------------- |
| 1개 : 단일 회귀    | 선형 : 선형 회귀     |
| 여러개 : 다중 회귀 | 비선형 : 비선형 회귀 |

* 대표적인 선형 회귀 모델

  * 일반 선형 회귀
  * 릿지
  * 라쏘
  * 엘라스틱넷
  * 로지스틱 회귀(분류)

* 잔차 : 실제 값과 회귀 모델의 차이에 따른 오류 값 ->최적의 회귀는 이 잔차를 최소가 되는 모델을 만든다는 의미

* 오류의 값은 +나 -가 될 수 있기때문에 오류의 합을 구하기 위해 단순 덧셈뺄셈은 뜻하지 않게 오류 합이 크게 줄어들 수 있음 -> RSS 사용

* RSS : 오류 값의 제곱을 구해서 더하는 방식
  $$
  RSS = Error^2
  $$

* 회귀에서 이 RSS는 비용(Cost)이며 w 변수로 구성되는 RSS를 비용함수(손실함수)라고 함

$$
RSS(w_0,w_1) = \frac{1}{N}\displaystyle\sum_{i=1}^{N} (y_i-(w_0+w_1*x_i))^2
$$

### 경사 하강법

* 경사하강법(Gradient Descent)은 1차 근삿값 발견용 **최적화 알고리즘**이다. 기본 개념은 함수의 기울기(경사)를 구하고 경사의 절댓값이 낮은 쪽으로 계속 이동시켜 극값에 이를 때까지 반복시키는 것이다.
* 딥러닝에 있어서 가장 중요한 개념중 하나

